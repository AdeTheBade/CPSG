{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"/Users/badekale/Documents/Hamoyeew/Subfolders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in the folder: 52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "subfolders = sorted([folder for folder in os.listdir(pdf_folder_path) if os.path.isdir(os.path.join(pdf_folder_path, folder))])\n",
    "print(f\"Total files in the folder: {len(subfolders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "from IPython.display import Markdown\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: COP28\n",
      "Loaded and processed: cp2023_11a01E.pdf\n",
      "Loaded and processed: cp2023_11a02E.pdf\n",
      "Processing folder: CMP18\n",
      "Loaded and processed: cmp2023_09a01E.pdf\n",
      "Processing folder: CMA5\n",
      "Loaded and processed: cma2023_16a01E.pdf\n",
      "Loaded and processed: cma2023_16a02E.pdf\n",
      "Loaded and processed: cma2023_16a03E.pdf\n",
      "Processing folder: COP27\n",
      "Loaded and processed: cp2022_10a01_E.pdf\n",
      "Loaded and processed: cp2022_10a02E.pdf\n",
      "Loaded and processed: cp2022_10a03E.pdf\n",
      "Processing folder: CMP17\n",
      "Loaded and processed: cmp2022_09a01E.pdf\n",
      "Processing folder: CMA4\n",
      "Loaded and processed: cma2022_10_a01E.pdf\n",
      "Loaded and processed: cma2022_10a03E.pdf\n",
      "Loaded and processed: cma2023_10a02E.pdf\n",
      "Processing folder: COP26\n",
      "Loaded and processed: cp2021_12_add1E.pdf\n",
      "Loaded and processed: cp2021_12a02E.pdf\n",
      "Processing folder: CMP16\n",
      "Loaded and processed: cmp2021_08_add1E.pdf\n",
      "Processing folder: CMA3\n",
      "Loaded and processed: CMA2021_10_Add3_E.pdf\n",
      "Loaded and processed: CMA2021_L10a2E.pdf\n",
      "Loaded and processed: cma2021_10a01E.pdf\n",
      "Processing folder: COP25\n",
      "Loaded and processed: cp2019_13_a02E.pdf\n",
      "Loaded and processed: cp2019_13a01E.pdf\n",
      "Processing folder: CMP15\n",
      "Loaded and processed: cmp2019_08a01E.pdf\n",
      "Processing folder: CMA2\n",
      "Loaded and processed: cma2019_06a01E.pdf\n",
      "Processing folder: COP24\n",
      "Loaded and processed: 10a1.pdf\n",
      "Loaded and processed: 10a2e.pdf\n",
      "Processing folder: CMP14\n",
      "Loaded and processed: 08a1e.pdf\n",
      "Processing folder: CMA1\n",
      "Loaded and processed: 03a01.pdf\n",
      "Loaded and processed: CMA2018_03a02E.pdf\n",
      "Loaded and processed: cma2018_03a01E.pdf\n",
      "Processing folder: COP23\n",
      "Loaded and processed: 11a01.pdf\n",
      "Loaded and processed: 11a02.pdf\n",
      "Processing folder: CMP13\n",
      "Loaded and processed: 07a01-6.pdf\n",
      "Processing folder: COP22\n",
      "Loaded and processed: 10a01.pdf\n",
      "Loaded and processed: 10a02.pdf\n",
      "Processing folder: CMP12\n",
      "Loaded and processed: 08a01-2.pdf\n",
      "Processing folder: COP21\n",
      "Loaded and processed: 10a01-2.pdf\n",
      "Loaded and processed: 10a02-2.pdf\n",
      "Loaded and processed: 10a03.pdf\n",
      "Processing folder: CMP11\n",
      "Loaded and processed: 08a01-3.pdf\n",
      "Loaded and processed: 08a02-2.pdf\n",
      "Processing folder: COP20\n",
      "Loaded and processed: 10a01-3.pdf\n",
      "Loaded and processed: 10a02-3.pdf\n",
      "Loaded and processed: 10a03-2.pdf\n",
      "Processing folder: CMP10\n",
      "Loaded and processed: 09a01-2.pdf\n",
      "Processing folder: COP19\n",
      "Loaded and processed: 10a01-4.pdf\n",
      "Loaded and processed: 10a02r01.pdf\n",
      "Loaded and processed: 10a03-3.pdf\n",
      "Processing folder: CMP9\n",
      "Loaded and processed: 09a01-3.pdf\n",
      "Processing folder: COP18\n",
      "Loaded and processed: 08a01.pdf\n",
      "Loaded and processed: 08a02.pdf\n",
      "Loaded and processed: 08a03.pdf\n",
      "Processing folder: CMP8\n",
      "Loaded and processed: 13a02-2.pdf\n",
      "Loaded and processed: 13a02c01.pdf\n",
      "Processing folder: COP17\n",
      "Loaded and processed: 09a01.pdf\n",
      "Loaded and processed: 09a02.pdf\n",
      "Processing folder: CMP7\n",
      "Loaded and processed: 10a01-6.pdf\n",
      "Loaded and processed: 10a02-5.pdf\n",
      "Processing folder: COP16\n",
      "Loaded and processed: 07a01.pdf\n",
      "Loaded and processed: 07a02.pdf\n",
      "Processing folder: CMP6\n",
      "Loaded and processed: 12a01.pdf\n",
      "Processing folder: COP15\n",
      "Loaded and processed: 11a01-2.pdf\n",
      "Processing folder: CMP5\n",
      "Loaded and processed: 21a01.pdf\n",
      "Processing folder: COP14\n",
      "Loaded and processed: 07a01-2.pdf\n",
      "Processing folder: CMP4\n",
      "Loaded and processed: 11a02-2.pdf\n",
      "Processing folder: COP13\n",
      "Loaded and processed: 06a01.pdf\n",
      "Processing folder: CMP3\n",
      "Loaded and processed: 09a01-4.pdf\n",
      "Processing folder: COP12\n",
      "Loaded and processed: 05a01.pdf\n",
      "Processing folder: CMP2\n",
      "Loaded and processed: 10a01-7.pdf\n",
      "Processing folder: COP11\n",
      "Loaded and processed: 05a01-2.pdf\n",
      "Processing folder: CMP1\n",
      "Loaded and processed: 08a01-4.pdf\n",
      "Loaded and processed: 08a02-3.pdf\n",
      "Loaded and processed: 08a03-2.pdf\n",
      "Loaded and processed: 08a04.pdf\n",
      "Processing folder: COP10\n",
      "Loaded and processed: 10a01-5.pdf\n",
      "Loaded and processed: 10a02-4.pdf\n",
      "Processing folder: COP9\n",
      "Loaded and processed: 06a01-2.pdf\n",
      "Loaded and processed: 06a02.pdf\n",
      "Processing folder: COP8\n",
      "Loaded and processed: 07a01-3.pdf\n",
      "Loaded and processed: 07a02-2.pdf\n",
      "Loaded and processed: 07a03.pdf\n",
      "Processing folder: COP7-1\n",
      "Loaded and processed: 05a01-3.pdf\n",
      "Processing folder: COP7-2\n",
      "Loaded and processed: 13a01.pdf\n",
      "Loaded and processed: 13a02.pdf\n",
      "Loaded and processed: 13a03.pdf\n",
      "Loaded and processed: 13a04.pdf\n",
      "Processing folder: COP6\n",
      "Loaded and processed: 05a02.pdf\n",
      "Processing folder: COP5\n",
      "Loaded and processed: 06a01-3.pdf\n",
      "Processing folder: COP4\n",
      "Loaded and processed: 16a01.pdf\n",
      "Processing folder: COP3\n",
      "Loaded and processed: 07a01-4.pdf\n",
      "Processing folder: COP2\n",
      "Loaded and processed: 15a01.pdf\n",
      "Processing folder: COP1\n",
      "Loaded and processed: 07a01-5.pdf\n"
     ]
    }
   ],
   "source": [
    "subfolders = [folder for folder in os.listdir(pdf_folder_path) if os.path.isdir(os.path.join(pdf_folder_path, folder))]\n",
    "\n",
    "# Function to sort subfolders separately by type (COP, CMP, CMA) in descending order\n",
    "def custom_sort_key(folder_name):\n",
    "    # Match COP, CMP, CMA with their numbers\n",
    "    match = re.match(r\"(COP|CMP|CMA)(\\d+)\", folder_name)\n",
    "    if match:\n",
    "        conference_type = match.group(1)\n",
    "        number = int(match.group(2))\n",
    "        if conference_type == \"COP\":\n",
    "            return (0, -number)  # Sort COP first in descending order\n",
    "        elif conference_type == \"CMP\":\n",
    "            return (1, -number)  # CMP comes after COP, in descending order\n",
    "        elif conference_type == \"CMA\":\n",
    "            return (2, -number)  # CMA comes last, in descending order\n",
    "    return (3, folder_name)  # Default case if no match\n",
    "\n",
    "# Sort the subfolders by type (COP, CMP, CMA)\n",
    "cop_subfolders = [folder for folder in subfolders if \"COP\" in folder]\n",
    "cmp_subfolders = [folder for folder in subfolders if \"CMP\" in folder]\n",
    "cma_subfolders = [folder for folder in subfolders if \"CMA\" in folder]\n",
    "\n",
    "# Sort each list in descending order\n",
    "cop_subfolders.sort(key=custom_sort_key)\n",
    "cmp_subfolders.sort(key=custom_sort_key)\n",
    "cma_subfolders.sort(key=custom_sort_key)\n",
    "\n",
    "# Create a list to store the final ordered subfolders by alternating COP, CMP, and CMA\n",
    "final_order = []\n",
    "\n",
    "# Find the maximum number of COP, CMP, and CMA folders to ensure alternating\n",
    "max_length = max(len(cop_subfolders), len(cmp_subfolders), len(cma_subfolders))\n",
    "\n",
    "# Alternate between COP, CMP, and CMA\n",
    "for i in range(max_length):\n",
    "    if i < len(cop_subfolders):\n",
    "        final_order.append(cop_subfolders[i])\n",
    "    if i < len(cmp_subfolders):\n",
    "        final_order.append(cmp_subfolders[i])\n",
    "    if i < len(cma_subfolders):\n",
    "        final_order.append(cma_subfolders[i])\n",
    "\n",
    "# Create a list to store the documents\n",
    "documents = []\n",
    "\n",
    "# Initialize a counter for the number of PDFs ingested\n",
    "pdf_count = 0\n",
    "\n",
    "# Function to load and process PDFs from each subfolder\n",
    "def load_pdfs_from_subfolders(pdf_folder_path, final_order):\n",
    "    global pdf_count\n",
    "\n",
    "    for subfolder in final_order:\n",
    "        # Get the path for the current subfolder\n",
    "        subfolder_path = os.path.join(pdf_folder_path, subfolder)\n",
    "        \n",
    "        # List all PDFs in the subfolder and sort them\n",
    "        files_in_subfolder = sorted([file for file in os.listdir(subfolder_path) if file.endswith('.pdf')])\n",
    "\n",
    "        # Print the subfolder name being processed\n",
    "        print(f\"Processing folder: {subfolder}\")\n",
    "\n",
    "        # Load each PDF in the subfolder\n",
    "        for file_name in files_in_subfolder:\n",
    "            pdf_path = os.path.join(subfolder_path, file_name)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            doc = loader.load()\n",
    "            \n",
    "            # Add the loaded document to the list\n",
    "            documents.extend(doc)\n",
    "            \n",
    "            # Increment the PDF counter\n",
    "            global pdf_count\n",
    "            pdf_count += 1\n",
    "            print(f'Loaded and processed: {file_name}')\n",
    "\n",
    "# Load PDFs from the sorted subfolders\n",
    "load_pdfs_from_subfolders(pdf_folder_path, final_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PDFs ingested: 91\n",
      "Total number of document chunks: 12339\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of PDFs ingested: {pdf_count}\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f'Total number of document chunks: {len(chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "ollama = OllamaLLM(\n",
    "    base_url=\"http://localhost:11434\",  \n",
    "    model=\"llama3.2:3b\",  \n",
    "    temperature=0,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory='/Users/badekale/Documents/Hamoyeew/chroma001'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ollama,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Generate potential future climate policy scenarios for Sub-Saharan Africa that focus on accelerating renewable energy adoption. Consider policy incentives, grid integration challenges, and mechanisms for ensuring equitable access to clean energy.\"\n",
    "    \"Develop climate policy scenarios in which Sub-Saharan Africa prioritizes energy efficiency as a pillar of sustainable development. Include regulatory frameworks, financial incentives, and projected long-term benefits.\"\n",
    "    \"Propose future policy pathways that drive equitable access to renewable energy solutions in off-grid communities across Sub-Saharan Africa. Explore community-led initiatives, financing models, and regulatory support.\"\n",
    "    \"Develop climate policy scenarios where Sub-Saharan Africa prioritizes green hydrogen as a key energy export. Explore how governments might incentivize production, build supporting infrastructure, and navigate geopolitical opportunities and risks in global energy markets.\"\n",
    "    \"Imagine future climate policy scenarios where Sub-Saharan Africa invests heavily in research and development of new climate technologies. Highlight key focus areas, potential breakthroughs, and the role of international collaboration.\"\n",
    "    \"Generate scenarios in which artificial intelligence (AI) and digital technologies are integrated into climate policy implementation across Sub-Saharan Africa. Consider applications in emissions monitoring, predictive modeling, and adaptive policymaking.\"\n",
    "    \"Explore different climate policy scenarios in which Sub-Saharan Africa reduces fossil fuel dependency and transitions to a clean energy economy. Consider pathways that emphasize economic diversification, workforce retraining initiatives, and regulatory reforms.\"\n",
    "    \"Develop climate policy scenarios in which Sub-Saharan Africa adopts carbon pricing and emissions trading as primary tools for reducing greenhouse gas emissions. Consider potential economic benefits, implementation hurdles, and regional cooperation models.\"\n",
    "    \"Explore policy scenarios where Sub-Saharan Africa integrates circular economy principles into energy policy to promote sustainability. Discuss waste-to-energy innovations, material reuse, and industrial symbiosis.\"\n",
    "    \"Explore viable climate policy scenarios in which Sub-Saharan Africa adopts nuclear energy as part of its energy transition. Discuss key regional and international partnerships (e.g., IAEA, COP agreements), infrastructure development needs, and financial feasibility.\"\n",
    "    \"Develop climate policy scenarios for reducing transportation-related emissions in Sub-Saharan Africa. Discuss policy incentives for electric vehicle adoption, challenges in urban transport planning, and the role of biofuels and hydrogen as alternative energy sources.\"\n",
    "    \"Imagine future scenarios where decentralized energy efficiency initiatives significantly reduce energy poverty in Sub-Saharan Africa. Highlight local innovations, policy enablers, and community-driven approaches.\"\n",
    "    \"Develop potential future climate policy scenarios for Sub-Saharan Africa that emphasize sustainable land use and afforestation. Consider incentives for reforestation, carbon sequestration policies, and indigenous land management practices.\"\n",
    "    \"Generate possible future scenarios where Sub-Saharan Africa accelerates climate finance through international funding mechanisms. Consider public-private partnerships, sovereign green bonds, and risk mitigation strategies.\"\n",
    "    \"Propose detailed policy scenarios for Sub-Saharan Africa that strengthen institutional capacity for climate adaptation. Address governance reforms, inter-agency coordination, and financial resource allocation.\"\n",
    "    \"Explore future policy pathways where Sub-Saharan Africa mainstreams climate adaptation into national development plans. Discuss cross-sectoral collaboration, funding integration, and legislative frameworks.\"\n",
    "    \"Explore policy pathways where indigenous knowledge and local community-led solutions shape climate adaptation strategies in Sub-Saharan Africa. Consider land rights, traditional resource management practices, and equitable governance structures.\"\n",
    "    \"Generate policy scenarios where empowering local communities through climate education and advocacy leads to stronger grassroots climate action. Include capacity-building initiatives, knowledge-sharing platforms, and policy uptake metrics.\"\n",
    "    \"Imagine future climate policy scenarios where capacity building for climate governance strengthens institutional responses to climate challenges in Sub-Saharan Africa. Consider skills development, stakeholder collaboration, and policy implementation.\"\n",
    "    \"Please generate potential future policy scenarios for Sub-Saharan Africa that focus on building climate-resilient infrastructure—particularly around water management and disaster risk reduction. Include plausible timeframes, critical actors, and key funding mechanisms.\"\n",
    "    \"Propose detailed policy scenarios for Sub-Saharan Africa focusing on the health sector's adaptation to climate-induced challenges, such as heatwaves, vector-borne diseases, and flood-related health crises. Include metrics and expected outcomes.\"\n",
    "    \"Generate possible future scenarios in which Sub-Saharan Africa accelerates green finance for large-scale renewable energy projects. Consider international donors, private capital, and novel funding mechanisms, and explain major opportunities and risks.\"\n",
    "    \"What are potential future climate policy pathways in Sub-Saharan Africa if carbon markets and offset schemes become mainstream? Outline how governments, regional bodies, and local communities might participate or benefit.\"\n",
    "    \"Imagine several policy scenarios in which external technology transfer accelerates. How might local institutions be strengthened to adopt, maintain, and innovate on climate-related technologies (e.g., solar, wind, climate-smart agriculture)?\"\n",
    "    \"Generate a set of climate policy scenarios for Sub-Saharan Africa that show how collaboration between local, national, and regional bodies might evolve. Include considerations of political will, stakeholder conflicts, and resource allocation.\"\n",
    "    \"Develop future policy pathways in which local communities and grassroots movements play a pivotal role in shaping national climate strategies. Consider equity issues, social inclusion, and mechanisms for ensuring marginalized groups have a voice.\"\n",
    "    \"Propose climate policy scenarios addressing transboundary resource management (e.g., shared water basins, pastoral lands) in Sub-Saharan Africa. Explore how climate stressors could exacerbate conflict or incentivize deeper regional cooperation.\"\n",
    "    \"Please propose climate policy scenarios that prioritize mitigation efforts with the largest public-health co-benefits, such as reducing indoor air pollution from traditional biomass cooking. Include measurable outcomes and ethical considerations.\"\n",
    "    \"Describe a range of worst-case business as usual climate policy scenarios for Sub-Saharan Africa. Consider political inertia, minimal international support, and accelerating climate impacts, and explore the long-term social and economic consequences.\"\n",
    "    \"Generate scenarios in which Sub-Saharan Africa experiences more extreme climate impacts than currently predicted. How might governments, communities, and private actors innovate or pivot policy approaches in this high-risk future?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare generated responses to conform to RAGAS framework\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Traversing each question and passing into the chain to get answers from the system\n",
    "for question in questions:\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    # Extract the `page_content` from the retrieved documents as a list\n",
    "    formatted_contexts = [doc.page_content for doc in relevant_docs]  # Keep this as a list of strings\n",
    "    \n",
    "    # Get the response from the RAG chain\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    # Extract the 'result' field\n",
    "    if isinstance(response, dict) and \"result\" in response:\n",
    "        answers.append(response[\"result\"])\n",
    "    else:\n",
    "        answers.append(response)\n",
    "    \n",
    "    contexts.append(formatted_contexts)  # Append as a list\n",
    "\n",
    "# Prepare the dataset\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,  # Ensure this remains a list of strings\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a HuggingFace Dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate dataset structure\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ContextUtilization,\n",
    "    AnswerRelevancy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_mistral = OllamaLLM(\n",
    "    model=\"mistral:7b\",\n",
    "    verbose=False,\n",
    "    timeout=150,  \n",
    "    num_ctx=5000,  \n",
    "    disable_streaming=False,\n",
    "    temperature=0  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gemma2 = OllamaLLM(\n",
    "    model=\"gemma2:2b\",\n",
    "    verbose=False,\n",
    "    timeout=600,  \n",
    "    num_ctx=5000,  \n",
    "    disable_streaming=False,\n",
    "    temperature=0  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_nomic = OllamaEmbeddings(model=\"nomic-embed-text:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate prompt responses one by one\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "# Iterate through each sample in the dataset and evaluate it separately\n",
    "for i, sample in enumerate(dataset):\n",
    "    print(f\"Evaluating sample {i+1}/{len(dataset)}...\")  \n",
    "\n",
    "    # Create a single-item dataset for this sample\n",
    "    single_sample_dataset = Dataset.from_dict({\n",
    "        \"question\": [sample[\"question\"]],\n",
    "        \"answer\": [sample[\"answer\"]],\n",
    "        \"contexts\": [sample[\"contexts\"]]\n",
    "    })\n",
    "\n",
    "    # Perform evaluation on the single sample\n",
    "    result_mistral = evaluate(\n",
    "        dataset=single_sample_dataset,\n",
    "        metrics=[Faithfulness(), ContextUtilization(), AnswerRelevancy()],\n",
    "        llm=llm_mistral,\n",
    "        embeddings=embeddings_nomic,\n",
    "        run_config=RunConfig(max_workers=16, timeout=600, max_retries=5, max_wait=20, log_tenacity=True)\n",
    "    )\n",
    "\n",
    "    # Extract metric scores\n",
    "    scores = {metric: result_mistral[metric][0] if result_mistral[metric] else \"NaN\" for metric in result_mistral._scores_dict.keys()}\n",
    "\n",
    "    # Prepare a row for storing the result\n",
    "    evaluation_results.append({\n",
    "        \"Question\": sample[\"question\"],\n",
    "        \"Answer\": sample[\"answer\"],\n",
    "        \"Contexts\": \" | \".join(sample[\"contexts\"]),\n",
    "        \"Faithfulness\": scores.get(\"faithfulness\", \"NaN\"),\n",
    "        \"ContextUtilization\": scores.get(\"context_utilization\", \"NaN\"),\n",
    "        \"AnswerRelevancy\": scores.get(\"answer_relevancy\", \"NaN\")\n",
    "    })\n",
    "\n",
    "    print(f\"Sample {i+1} evaluation completed.\\n\")\n",
    "\n",
    "\n",
    "evaluated_data = evaluation_results\n",
    "print(\"Evaluation completed. Ready to save results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "\n",
    "# Iterate through each sample in the dataset and evaluate it separately\n",
    "for i, sample in enumerate(dataset):\n",
    "    print(f\"Evaluating sample {i+1}/{len(dataset)}...\")  \n",
    "\n",
    "    # Create a single-item dataset for this sample\n",
    "    single_sample_dataset = Dataset.from_dict({\n",
    "        \"question\": [sample[\"question\"]],\n",
    "        \"answer\": [sample[\"answer\"]],\n",
    "        \"contexts\": [sample[\"contexts\"]]\n",
    "    })\n",
    "\n",
    "    # Perform evaluation on the single sample\n",
    "    result_gemma2 = evaluate(\n",
    "        dataset=single_sample_dataset,\n",
    "        metrics=[Faithfulness(), ContextUtilization(), AnswerRelevancy()],\n",
    "        llm=llm_gemma2,\n",
    "        embeddings=embeddings_nomic,\n",
    "        run_config=RunConfig(max_workers=16, timeout=600, max_retries=5, max_wait=20, log_tenacity=True)\n",
    "    )\n",
    "\n",
    "    # Extract metric scores\n",
    "    scores = {metric: result_mistral[metric][0] if result_mistral[metric] else \"NaN\" for metric in result_mistral._scores_dict.keys()}\n",
    "\n",
    "    # Prepare a row for storing the result\n",
    "    evaluation_results.append({\n",
    "        \"Question\": sample[\"question\"],\n",
    "        \"Answer\": sample[\"answer\"],\n",
    "        \"Contexts\": \" | \".join(sample[\"contexts\"]),\n",
    "        \"Faithfulness\": scores.get(\"faithfulness\", \"NaN\"),\n",
    "        \"ContextUtilization\": scores.get(\"context_utilization\", \"NaN\"),\n",
    "        \"AnswerRelevancy\": scores.get(\"answer_relevancy\", \"NaN\")\n",
    "    })\n",
    "\n",
    "    print(f\"Sample {i+1} evaluation completed.\\n\")\n",
    "\n",
    "\n",
    "evaluated_data2 = evaluation_results\n",
    "print(\"Evaluation completed. Ready to save results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(evaluated_data)\n",
    "\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the folder where the file will be saved\n",
    "folder_path = os.path.expanduser(\"/Users/badekale/Documents/Hamoyeew/SUB\")\n",
    "\n",
    "# Create the folder if it doesn't already exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the full file path\n",
    "output_file = os.path.join(folder_path, \"evaluation_results.csv\")\n",
    "\n",
    "# Define the CSV header\n",
    "header = [\"Question\", \"Answer\", \"Contexts\", \"Faithfulness\", \"ContextUtilization\", \"AnswerRelevancy\"]\n",
    "\n",
    "# Write all results to CSV at once\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(evaluated_data)\n",
    "\n",
    "print(f\"All evaluation results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
